---
title: "Mini Learning Analytics Assignment - Natural Language Processing"
output: html_document
df_print: paged
author: Renato Russo
date: March, 30, 2022
---
# About this project
This is a notebook that documents my first natural language processing project, in which I scrape Twitter data on the war in Ukraine. I collect tweets using three different keywords in two different moments--at the very start of the conflict and 20 days into the war.

1. __Tweets containing the term "Ukraine"__. These publications are a sort of "control group." They are intended to measure general perceptions about the conflict, without any other filters besides time of publication and, obviously the ability and intention to publish tweets. This would represent the control group.
2. __Tweets containing the terms "Ukraine" and "CNN"__. The intent here is evaluating publications that make reference to a mainstream media outlet. This would represent one of the "treatment groups."
3. __Tweets containing the terms "Ukraine" and "Breitbart"__. This would represent a sample of tweets that are associated with a right-wing website. This is the other "treatment group."

My interest is in evaluating the differences in perception about the war according to exposure to media with different political orientation. Breitbart is clearly right-wing and CNN, in my opinion, is moderate, although [there are claims that it is left-](https://www.allsides.com/news-source/cnn-media-bias) and that [it is right-wing](https://www.democraticunderground.com/100271183). I collected tweets since February 24 (representing "natural state" of opinions) and data in this project covers the tweets until March 10. Latest tweets would represent the effect of 3 weeks of media coverage.

## Data preparation of each subset {.tabset}

### General/early
```{r}
library(tidyverse)
```

```{r}
# GENERAL TWEETS FIRST DAYS ---------------------------------------------
load("/Users/renatorusso/Desktop/TLTLAB/Ukraine analysis/ukraine_feb_24.Rda")
ukr_early1 <- as_tibble(ukraine_feb_24_real)

# DATA CLEANING AND WRANGLING ---------------------------------------------
## creating a function to remove numbers and punctuation
## in preliminary analysis, I noticed that the prevalence of "Ukraine" made it
## challenging to draw any conclusion from the sentiment analysis, so I decided 
## to remove it too. I'm also using the custom function to remove a few words
## detected when I ran posterior parts of this analysis

clean_text <- function(text) {
  text <- tolower(text)
  text <- gsub("[[:digit:]]+", "", text)
  text <- gsub("[[:punct:]]+", "", text)
  text <- gsub("ukraine", "", text)
  return(text)
}

## cleaning the text
ukr_early1$text <- clean_text(ukr_early1$text)

## tokenizing the words in the "text" column
tweets_token <- ukr_early1 %>% 
  tidytext::unnest_tokens(word, text) %>% 
  count(status_id, word)

tweets_token

## removing stop words from tidy text's standard library
tweets_token <- tweets_token %>% 
  anti_join(tidytext::get_stopwords())

## removing more stop words by creating a custom list of stop words that appeared
## when I first ran posterior parts of this analysis
my_stopwords_ukr <- tibble(word = c(as.character(1:10),
                                    "like", "dont", "de", "la", "en",
                                    "amp", "et", "le", "les", "I", "Ã ", "des", "pas",
                                    "guerre", "russie", "cest", "krieg", "breitbartnews",
                                    "cnn", "msnbc", "foxnews"))

tweets_token <- tweets_token %>% 
  anti_join(my_stopwords_ukr)

## creating a document-text matrix
DTM <- tweets_token %>% 
  tidytext::cast_dtm(status_id, word, n)

DTM

# EXPLORATORY ANALYSIS ----------------------------------------------------
## looking at the document-term matrix
tweets_token %>% 
  group_by(word) %>% 
  summarize(occurrence = sum(n)) %>% 
  arrange(desc(occurrence))


# TOPIC MODELING ----------------------------------------------------------
library(topicmodels)
## running Latent Drichlet Allocation (LDA)
LDA <- topicmodels::LDA(DTM, k = 4, control = list(seed = 123))
LDA_td <- tidytext::tidy(LDA)
LDA_td

## visualizing topics using ggplot2() and tidytext()
library(tidytext)

topTerms <- LDA_td %>% 
  group_by(topic) %>% 
  top_n(7, beta) %>% 
  arrange(topic, -beta)

theme_set(theme_bw())

topTerms %>% 
  mutate(term = reorder_within(term, beta, topic)) %>% 
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free_x") +
  coord_flip() +
  scale_x_reordered() +
  labs(title = "Topics in general tweets early in the war")

library(widyr)
word_pairs_ukr_early <- tweets_token %>% 
  pairwise_count(word, status_id, sort = TRUE, upper = FALSE)

#network of co-occurring words
library(ggplot2)
library(igraph)
library(ggraph)

word_pairs_ukr_early %>%
  filter(n >= 200) %>%
  graph_from_data_frame() %>%
  ggraph(layout = "fr") +
  geom_edge_link(aes(edge_alpha = n, edge_width = n), edge_colour = "cyan4") +
  geom_node_point(size = 5) +
  geom_node_text(aes(label = name), repel = TRUE, 
                 point.padding = unit(0.2, "lines")) +
  theme_void() +
  labs(title = "Co-occurring terms in general tweets early in the war")


# GENERAL TWEETS 20 DAYS INTO THE WAR ---------------------------------------------
load("/Users/renatorusso/ukraine_mar_16.Rda")
ukr_20 <- as_tibble(ukraine_mar_16)

# DATA CLEANING AND WRANGLING ---------------------------------------------

## cleaning the text
ukr_20$text <- clean_text(ukr_20$text)

## tokenizing the words in the "text" column
tweets_token_20 <- ukr_20 %>% 
  tidytext::unnest_tokens(word, text) %>% 
  count(status_id, word)

## removing stop words from tidy text's standard library
tweets_token_20 <- tweets_token_20 %>% 
  anti_join(stop_words)

## words in German and French have not been removed with the "stop_words" native
## dataset (and they appear a lot), so I'll try to include the word databases 
## "manually"
stop_german <- data.frame(word = stopwords::stopwords("de"), stringsAsFactors = FALSE)

stop_french <- data.frame(word = stopwords::stopwords("fr"), stringsAsFactors = FALSE)

tweets_token_20 <-  tweets_token_20 %>% 
  anti_join(stop_words, by = c('word')) %>%
  anti_join(stop_german, by = c("word")) %>% 
  anti_join(stop_french, by = c("word"))

tweets_token_20 <- tweets_token_20 %>% 
  anti_join(my_stopwords_ukr)

## creating a document-text matrix
DTM_20 <- tweets_token_20 %>% 
  tidytext::cast_dtm(status_id, word, n)

# EXPLORATORY ANALYSIS ----------------------------------------------------
## looking at the document-term matrix
tweets_token_20 %>% 
  group_by(word) %>% 
  summarize(occurrence = sum(n)) %>% 
  arrange(desc(occurrence))


# TOPIC MODELING ----------------------------------------------------------
#library(topicmodels)
## running Latent Drichlet Allocation (LDA)
LDA_20 <- topicmodels::LDA(DTM_20, k = 4, control = list(seed = 123))
LDA_td_20 <- tidytext::tidy(LDA_20)
LDA_td_20

topTerms_20 <- LDA_td_20 %>% 
  group_by(topic) %>% 
  top_n(7, beta) %>% 
  arrange(topic, -beta)

topTerms_20 %>% 
  mutate(term = reorder_within(term, beta, topic)) %>% 
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free_x") +
  coord_flip() +
  scale_x_reordered() +
  labs(title = "Topics in general tweets 20 days into the war")

word_pairs_ukr_20 <- tweets_token_20 %>% 
  pairwise_count(word, status_id, sort = TRUE, upper = FALSE)

#network of co-occurring words
word_pairs_ukr_20 %>%
  filter(n >= 100) %>%
  graph_from_data_frame() %>%
  ggraph(layout = "fr") +
  geom_edge_link(aes(edge_alpha = n, edge_width = n), edge_colour = "cyan4") +
  geom_node_point(size = 5) +
  geom_node_text(aes(label = name), repel = TRUE, 
                 point.padding = unit(0.2, "lines")) +
  theme_void() +
  labs(title = "Co-occurring terms in general tweets 20 days into the war")

# CNN-RELATED EARLY TWEETS ---------------------------------------------
load("/Users/renatorusso/Desktop/TLTLAB/Ukraine analysis/ukraine_cnn_feb_25.Rda")
ukr_early_cnn <- as_tibble(ukraine_cnn_feb_25)

# DATA CLEANING AND WRANGLING ---------------------------------------------

## cleaning the text
ukr_early_cnn$text <- clean_text(ukr_early_cnn$text)

## tokenizing the words in the "text" column
tweets_token_cnn_early <- ukr_early_cnn %>% 
  tidytext::unnest_tokens(word, text) %>% 
  count(status_id, word)

## removing stop words from tidy text's standard library
tweets_token_cnn_early <- tweets_token_cnn_early %>% 
  anti_join(stop_words)

tweets_token_cnn_early <-  tweets_token_cnn_early %>% 
  anti_join(stop_words, by = c('word')) %>%
  anti_join(stop_german, by = c("word")) %>% 
  anti_join(stop_french, by = c("word"))

tweets_token_cnn_early <- tweets_token_cnn_early %>% 
  anti_join(my_stopwords_ukr)

## creating a document-text matrix
DTM_early_cnn <- tweets_token_cnn_early %>% 
  tidytext::cast_dtm(status_id, word, n)

# EXPLORATORY ANALYSIS ----------------------------------------------------
## looking at the document-term matrix
tweets_token_cnn_early %>% 
  group_by(word) %>% 
  summarize(occurrence = sum(n)) %>% 
  arrange(desc(occurrence))


# TOPIC MODELING ----------------------------------------------------------
#library(topicmodels)
## running Latent Drichlet Allocation (LDA)
LDA_cnn_early <- topicmodels::LDA(DTM_early_cnn, k = 4, control = list(seed = 123))
LDA_cnn_early_td <- tidytext::tidy(LDA_cnn_early)
LDA_cnn_early

topTerms_cnn_early <- LDA_cnn_early_td %>% 
  group_by(topic) %>% 
  top_n(7, beta) %>% 
  arrange(topic, -beta)

topTerms_cnn_early %>% 
  mutate(term = reorder_within(term, beta, topic)) %>% 
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free_x") +
  coord_flip() +
  scale_x_reordered() +
  labs(title = "Topics in CNN-related tweets early in the war")

word_pairs_cnn_early <- tweets_token_cnn_early %>% 
  pairwise_count(word, status_id, sort = TRUE, upper = FALSE)

## network of co-occurring words
word_pairs_cnn_early %>%
  filter(n >= 200) %>%
  graph_from_data_frame() %>%
  ggraph(layout = "fr") +
  geom_edge_link(aes(edge_alpha = n, edge_width = n), edge_colour = "cyan4") +
  geom_node_point(size = 5) +
  geom_node_text(aes(label = name), repel = TRUE, 
                 point.padding = unit(0.2, "lines")) +
  theme_void() +
  labs(title = "Co-occurring terms in CNN-related tweets early in the war")

# CNN-RELATED 20 DAYS INTO THE WAR ---------------------------------------------
load("/Users/renatorusso/ukraine_cnn_mar_16.Rda")
ukr_d20_cnn <- as_tibble(ukraine_cnn_mar_16)

# DATA CLEANING AND WRANGLING ---------------------------------------------

## cleaning the text
ukr_d20_cnn$text <- clean_text(ukr_d20_cnn$text)

## tokenizing the words in the "text" column
tweets_token_d20_cnn <- ukr_d20_cnn %>% 
  tidytext::unnest_tokens(word, text) %>% 
  count(status_id, word)

## removing stop words from tidy text's standard library
tweets_token_d20_cnn <- tweets_token_d20_cnn %>% 
  anti_join(stop_words)

tweets_token_d20_cnn <-  tweets_token_d20_cnn %>% 
  anti_join(stop_words, by = c('word')) %>%
  anti_join(stop_german, by = c("word")) %>% 
  anti_join(stop_french, by = c("word"))

tweets_token_d20_cnn <- tweets_token_d20_cnn %>% 
  anti_join(my_stopwords_ukr)

## creating a document-text matrix
DTM_d20_cnn <- tweets_token_d20_cnn %>% 
  tidytext::cast_dtm(status_id, word, n)

# EXPLORATORY ANALYSIS ----------------------------------------------------
## looking at the document-term matrix
tweets_token_d20_cnn %>% 
  group_by(word) %>% 
  summarize(occurrence = sum(n)) %>% 
  arrange(desc(occurrence))


# TOPIC MODELING ----------------------------------------------------------
#library(topicmodels)
## running Latent Drichlet Allocation (LDA)
LDA_d20_cnn <- topicmodels::LDA(DTM_d20_cnn, k = 4, control = list(seed = 123))
LDA_d20_cnn_td <- tidytext::tidy(LDA_d20_cnn)
LDA_d20_cnn

topTerms_d20_cnn <- LDA_d20_cnn_td %>% 
  group_by(topic) %>% 
  top_n(7, beta) %>% 
  arrange(topic, -beta)

topTerms_d20_cnn %>% 
  mutate(term = reorder_within(term, beta, topic)) %>% 
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free_x") +
  coord_flip() +
  scale_x_reordered() +
  labs(title = "Topics in CNN-related tweets 20 days into the war")

word_pairs_d20_cnn <- tweets_token_d20_cnn %>% 
  pairwise_count(word, status_id, sort = TRUE, upper = FALSE)

## network of co-occurring words
word_pairs_d20_cnn %>%
  filter(n >= 200) %>%
  graph_from_data_frame() %>%
  ggraph(layout = "fr") +
  geom_edge_link(aes(edge_alpha = n, edge_width = n), edge_colour = "cyan4") +
  geom_node_point(size = 5) +
  geom_node_text(aes(label = name), repel = TRUE, 
                 point.padding = unit(0.2, "lines")) +
  theme_void() +
  labs(title = "Co-occurring terms in CNN-related tweets 20 days into the war")

# BREITBART-RELATED EARLY TWEETS ---------------------------------------------
load("/Users/renatorusso/Desktop/TLTLAB/Ukraine analysis/ukraine_bb_feb_25.Rda")
ukr_early_bb <- as_tibble(ukraine_bb_feb_25)

# DATA CLEANING AND WRANGLING ---------------------------------------------

## cleaning the text
ukr_early_bb$text <- clean_text(ukr_early_bb$text)

## tokenizing the words in the "text" column
tweets_token_bb_early <- ukr_early_bb %>% 
  tidytext::unnest_tokens(word, text) %>% 
  count(status_id, word)

## removing stop words from tidy text's standard library
tweets_token_bb_early <- tweets_token_bb_early %>% 
  anti_join(stop_words)

tweets_token_bb_early <-  tweets_token_bb_early %>% 
  anti_join(stop_words, by = c('word')) %>%
  anti_join(stop_german, by = c("word")) %>% 
  anti_join(stop_french, by = c("word"))

tweets_token_bb_early <- tweets_token_bb_early %>% 
  anti_join(my_stopwords_ukr)

## creating a document-text matrix
DTM_early_bb <- tweets_token_bb_early %>% 
  tidytext::cast_dtm(status_id, word, n)

# EXPLORATORY ANALYSIS ----------------------------------------------------
## looking at the document-term matrix
tweets_token_bb_early %>% 
  group_by(word) %>% 
  summarize(occurrence = sum(n)) %>% 
  arrange(desc(occurrence))


# TOPIC MODELING ----------------------------------------------------------
#library(topicmodels)
## running Latent Drichlet Allocation (LDA)
LDA_bb_early <- topicmodels::LDA(DTM_early_bb, k = 4, control = list(seed = 123))
LDA_bb_early_td <- tidytext::tidy(LDA_bb_early)
LDA_bb_early

topTerms_bb_early <- LDA_bb_early_td %>% 
  group_by(topic) %>% 
  top_n(7, beta) %>% 
  arrange(topic, -beta)

topTerms_bb_early %>% 
  mutate(term = reorder_within(term, beta, topic)) %>% 
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free_x") +
  coord_flip() +
  scale_x_reordered() +
  labs(title = "Topics in Breitbart-related tweets early in the war")

word_pairs_bb_early <- tweets_token_bb_early %>% 
  pairwise_count(word, status_id, sort = TRUE, upper = FALSE)

## network of co-occurring words
word_pairs_bb_early %>%
  filter(n >= 50) %>%
  graph_from_data_frame() %>%
  ggraph(layout = "fr") +
  geom_edge_link(aes(edge_alpha = n, edge_width = n), edge_colour = "cyan4") +
  geom_node_point(size = 5) +
  geom_node_text(aes(label = name), repel = TRUE, 
                 point.padding = unit(0.2, "lines")) +
  theme_void() +
  labs(title = "Co-occurring terms in Breitbart-related tweets early in the war")

# BREITBART-RELATED 20 DAYS INTO THE WAR TWEETS ---------------------------------------------
load("/Users/renatorusso/ukraine_bb_mar_16.Rda")
ukr_d20_bb <- as_tibble(ukraine_bb_mar_16)

# DATA CLEANING AND WRANGLING ---------------------------------------------

## cleaning the text
ukr_d20_bb$text <- clean_text(ukr_d20_bb$text)

## tokenizing the words in the "text" column
tweets_token_d20_bb <- ukr_d20_bb %>% 
  tidytext::unnest_tokens(word, text) %>% 
  count(status_id, word)

## removing stop words from tidy text's standard library
tweets_token_d20_bb <- tweets_token_d20_bb %>% 
  anti_join(stop_words)

tweets_token_d20_bb <-  tweets_token_d20_bb %>% 
  anti_join(stop_words, by = c('word')) %>%
  anti_join(stop_german, by = c("word")) %>% 
  anti_join(stop_french, by = c("word"))

tweets_token_d20_bb <- tweets_token_d20_bb %>% 
  anti_join(my_stopwords_ukr)

## creating a document-text matrix
DTM_d20_bb <- tweets_token_d20_bb %>% 
  tidytext::cast_dtm(status_id, word, n)

# EXPLORATORY ANALYSIS ----------------------------------------------------
## looking at the document-term matrix
tweets_token_d20_bb %>% 
  group_by(word) %>% 
  summarize(occurrence = sum(n)) %>% 
  arrange(desc(occurrence))


# TOPIC MODELING ----------------------------------------------------------
#library(topicmodels)
## running Latent Drichlet Allocation (LDA)
LDA_d20_bb <- topicmodels::LDA(DTM_d20_bb, k = 4, control = list(seed = 123))
LDA_d20_bb_td <- tidytext::tidy(LDA_d20_bb)
LDA_d20_bb

topTerms_d20_bb <- LDA_d20_bb_td %>% 
  group_by(topic) %>% 
  top_n(7, beta) %>% 
  arrange(topic, -beta)

topTerms_d20_bb %>% 
  mutate(term = reorder_within(term, beta, topic)) %>% 
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free_x") +
  coord_flip() +
  scale_x_reordered() +
  labs(title = "Topics in Breitbart-related tweets 20-days into the war")

word_pairs_d20_bb <- tweets_token_d20_bb %>% 
  pairwise_count(word, status_id, sort = TRUE, upper = FALSE)

## network of co-occurring words
word_pairs_d20_bb %>%
  filter(n >= 20) %>%
  graph_from_data_frame() %>%
  ggraph(layout = "fr") +
  geom_edge_link(aes(edge_alpha = n, edge_width = n), edge_colour = "cyan4") +
  geom_node_point(size = 5) +
  geom_node_text(aes(label = name), repel = TRUE, 
                 point.padding = unit(0.2, "lines")) +
  theme_void() +
  labs(title = "Co-occurring terms in Breitbart-related tweets 20 days into the war")

```

Now that I have created all the charts, I'll replicate them here to make the comparison easier.

## Charts of most relevant topics {.tabset}

### General/early

```{r}
topTerms %>% 
  mutate(term = reorder_within(term, beta, topic)) %>% 
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free_x") +
  coord_flip() +
  scale_x_reordered() +
  labs(title = "Topics in general tweets early in the war")
```

### General/20 days

```{r}
topTerms_20 %>% 
  mutate(term = reorder_within(term, beta, topic)) %>% 
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free_x") +
  coord_flip() +
  scale_x_reordered() +
  labs(title = "Topics in general tweets 20 days into the war")
```

### CNN/early

```{r}
topTerms_cnn_early %>% 
  mutate(term = reorder_within(term, beta, topic)) %>% 
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free_x") +
  coord_flip() +
  scale_x_reordered() +
  labs(title = "Topics in CNN-related tweets early in the war")
```

### CNN/20 days

```{r}
topTerms_d20_cnn %>% 
  mutate(term = reorder_within(term, beta, topic)) %>% 
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free_x") +
  coord_flip() +
  scale_x_reordered() +
  labs(title = "Topics in CNN-related tweets 20 days into the war")
```

### Breitbart/early

```{r}
topTerms_bb_early %>% 
  mutate(term = reorder_within(term, beta, topic)) %>% 
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free_x") +
  coord_flip() +
  scale_x_reordered() +
  labs(title = "Topics in Breitbart-related tweets early in the war")
```

### Breitbart/20 days

```{r}
topTerms_d20_bb %>% 
  mutate(term = reorder_within(term, beta, topic)) %>% 
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free_x") +
  coord_flip() +
  scale_x_reordered() +
  labs(title = "Topics in Breitbart-related tweets 20-days into the war")
```

____

##### Early hours
|         |                            |                               |                           |
|---------|----------------------------|-------------------------------|---------------------------|
| Topic # | General                    | CNN-related                   | Breitbart-related         |
| 1       | Russia, Putin, war         | NATO and sanctions; Biden     | Oil; Trump; refugees      |
| 2       | Explosions heard           | Russian invasion; Europe      | Biden; sanctions; border  |
| 3       | Russian military operation | News coverage of the invasion | Russia; special operation |
| 4       | NATO; Putin; war           | Chernobyl; control            | Crisis; Biden; prices     |


#####  20 days into the war
|         |                            |                            |                            |
|---------|----------------------------|----------------------------|----------------------------|
| Topic # | General          | CNN-related              | Breitbart-related         |
| 1       | NATO support     | Zelensky, Biden, Putin   | Democrats; failure        |
| 2       | People/children  | China/Russia             | China; biological weapons |
| 3       | NATO, aid, Biden | Bomb in Mariupol theater | Poll; Trump               |
| 4       | Stop Putin       | NATO; Zelensky           | Documentary; Poland       |


As the tables above show, there are a few differences in each segment of the data set, such as:

__Connections to domestic issues__. In tweets mentioning Breitbart News, comments connecting the conflict with US domestic issues appear from the outset, as demonstrated by topics like "Trump," "border," and "crisis," associated with "Biden."

__China and biological weapons__ Tweets mentioning Breitbart 20 days into the war associate China and biological weapons, possibly connecting with a column published on the news website about the conspiracy theories about US-funded biological labs in Ukraine.


![alt text](/Users/renatorusso/Desktop/Ed.D./HUDK-4051/NLP-China-Breibart.png "Title")


__Domestic politics__ In Breitbart-related tweets, US domestic politics is salient. For example, Trump appears as one of the topics. Some tweets that mention the former president refer to a public opinion poll according to which there is belief that Russia would not invade Ukraine were Trump the US president.


## Charts of co-occurring terms {.tabset}

### General/early

```{r}
word_pairs_ukr_early %>%
  filter(n >= 200) %>%
  graph_from_data_frame() %>%
  ggraph(layout = "fr") +
  geom_edge_link(aes(edge_alpha = n, edge_width = n), edge_colour = "cyan4") +
  geom_node_point(size = 5) +
  geom_node_text(aes(label = name), repel = TRUE, 
                 point.padding = unit(0.2, "lines")) +
  theme_void() +
  labs(title = "Co-occurring terms in general tweets early in the war")
```

### General/20 days

```{r}
word_pairs_ukr_20 %>%
  filter(n >= 100) %>%
  graph_from_data_frame() %>%
  ggraph(layout = "fr") +
  geom_edge_link(aes(edge_alpha = n, edge_width = n), edge_colour = "cyan4") +
  geom_node_point(size = 5) +
  geom_node_text(aes(label = name), repel = TRUE, 
                 point.padding = unit(0.2, "lines")) +
  theme_void() +
  labs(title = "Co-occurring terms in general tweets 20 days into the war")
```

### CNN/early

```{r}
word_pairs_cnn_early %>%
  filter(n >= 200) %>%
  graph_from_data_frame() %>%
  ggraph(layout = "fr") +
  geom_edge_link(aes(edge_alpha = n, edge_width = n), edge_colour = "cyan4") +
  geom_node_point(size = 5) +
  geom_node_text(aes(label = name), repel = TRUE, 
                 point.padding = unit(0.2, "lines")) +
  theme_void() +
  labs(title = "Co-occurring terms in CNN-related tweets early in the war")
```

### CNN/20 days
```{r}
 word_pairs_d20_cnn %>%
  filter(n >= 250) %>%
  graph_from_data_frame() %>%
  ggraph(layout = "fr") +
  geom_edge_link(aes(edge_alpha = n, edge_width = n), edge_colour = "cyan4") +
  geom_node_point(size = 5) +
  geom_node_text(aes(label = name), repel = TRUE, 
                 point.padding = unit(0.2, "lines")) +
  theme_void() +
  labs(title = "Co-occurring terms in CNN-related tweets 20 days into the war")
```

### Breitbart/early

```{r}
  word_pairs_bb_early %>%
  filter(n >= 50) %>%
  graph_from_data_frame() %>%
  ggraph(layout = "fr") +
  geom_edge_link(aes(edge_alpha = n, edge_width = n), edge_colour = "cyan4") +
  geom_node_point(size = 5) +
  geom_node_text(aes(label = name), repel = TRUE, 
                 point.padding = unit(0.2, "lines")) +
  theme_void() +
  labs(title = "Co-occurring terms in Breitbart-related tweets early in the war")
```

### Breitbart/20 days
```{r}
word_pairs_d20_bb %>%
  filter(n >= 20) %>%
  graph_from_data_frame() %>%
  ggraph(layout = "fr") +
  geom_edge_link(aes(edge_alpha = n, edge_width = n), edge_colour = "cyan4") +
  geom_node_point(size = 5) +
  geom_node_text(aes(label = name), repel = TRUE, 
                 point.padding = unit(0.2, "lines")) +
  theme_void() +
  labs(title = "Co-occurring terms in Breitbart-related tweets 20 days into the war")

```

____

##### Noteworthy graph regions by subset of tweets
|         |                            |
|---------|----------------------------|
| Subset  | Noteworthy regions |
| General/early hours | Military operation; the UN reaction |
| General/20 days into | Biden's reaction; Trumps connection with Putin; political and economical consequences |
| CNN/early hours  | Russian approximation to Chernobyl; the role of NATO and sanctions |
| CNN/20 days into |  Mariupol theater |
| Breitbart/early hours  | Biden and crisis; Border agents being sent to Poland |
| Breitbart/20 days into | Censorship of Oliver Stone's documentary; war helping democrats divert attention  |

As seen above, the co-occurring terms charts also shows some differences across subsets at the two different moments. The Breitbart-related tweets seem to display stronger connections between the conflict and US domestic politics--a similar pattern found in the chart of topics.

----

My motivation for this analysis was identifying differences in perception about the war in Ukraine according to exposure to media with different political orientations, and, indeed, my analysis point to a few aspects that might be worth exploring in more depth. The most salient difference refers to the apparent sensitivity of a segment of users about the connections between the war and domestic issues. From the outset, tweets mentioning @BreitbartNews point to connections with former president Trump, the border crisis in the US, and the effects of the war in diverting the public's attention to more crucial issues--and how this might benefit Democrats.

One limitation of this analysis is that the volumes of tweets are considerably different across subsets: general tweets, obviously form an enormous subset, whereas CNN-related appear in a much lower volume, although still much higher than that of Breitbart related publications. Those differences are clear in the co-occurring charts, whose edges differ in order of magnitude (10s for Breitbart-related; hundreds for CNN-related; thousands for general).